{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOvdnh3qfC92TOkCUkIRaf1",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/krithikajain/bart_model_legal_summariser/blob/main/bart_model.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers\n",
        "!pip install nltk\n",
        "!pip install rouge_score"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6-XV5pzvaoDB",
        "outputId": "eae6b659-a36b-4a0d-e2f5-5ec4b2fa6651"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting transformers\n",
            "  Downloading transformers-4.28.0-py3-none-any.whl (7.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.0/7.0 MB\u001b[0m \u001b[31m16.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting huggingface-hub<1.0,>=0.11.0\n",
            "  Downloading huggingface_hub-0.13.4-py3-none-any.whl (200 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m200.1/200.1 kB\u001b[0m \u001b[31m21.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.9/dist-packages (from transformers) (4.65.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.9/dist-packages (from transformers) (1.22.4)\n",
            "Collecting tokenizers!=0.11.3,<0.14,>=0.11.1\n",
            "  Downloading tokenizers-0.13.3-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.8/7.8 MB\u001b[0m \u001b[31m74.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.9/dist-packages (from transformers) (6.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.9/dist-packages (from transformers) (3.11.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.9/dist-packages (from transformers) (2.27.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.9/dist-packages (from transformers) (2022.10.31)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.9/dist-packages (from transformers) (23.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.9/dist-packages (from huggingface-hub<1.0,>=0.11.0->transformers) (4.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.9/dist-packages (from requests->transformers) (2022.12.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.9/dist-packages (from requests->transformers) (2.0.12)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.9/dist-packages (from requests->transformers) (1.26.15)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.9/dist-packages (from requests->transformers) (3.4)\n",
            "Installing collected packages: tokenizers, huggingface-hub, transformers\n",
            "Successfully installed huggingface-hub-0.13.4 tokenizers-0.13.3 transformers-4.28.0\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.9/dist-packages (3.8.1)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.9/dist-packages (from nltk) (4.65.0)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.9/dist-packages (from nltk) (2022.10.31)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.9/dist-packages (from nltk) (1.2.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.9/dist-packages (from nltk) (8.1.3)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting rouge_score\n",
            "  Downloading rouge_score-0.1.2.tar.gz (17 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: absl-py in /usr/local/lib/python3.9/dist-packages (from rouge_score) (1.4.0)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.9/dist-packages (from rouge_score) (3.8.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.9/dist-packages (from rouge_score) (1.22.4)\n",
            "Requirement already satisfied: six>=1.14.0 in /usr/local/lib/python3.9/dist-packages (from rouge_score) (1.16.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.9/dist-packages (from nltk->rouge_score) (4.65.0)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.9/dist-packages (from nltk->rouge_score) (1.2.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.9/dist-packages (from nltk->rouge_score) (8.1.3)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.9/dist-packages (from nltk->rouge_score) (2022.10.31)\n",
            "Building wheels for collected packages: rouge_score\n",
            "  Building wheel for rouge_score (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for rouge_score: filename=rouge_score-0.1.2-py3-none-any.whl size=24954 sha256=c0926b78104efdedaea216ea58ec3fa981cff9d942e76ff799776127de2541a6\n",
            "  Stored in directory: /root/.cache/pip/wheels/9b/3d/39/09558097d3119ca0a4d462df68f22c6f3c1b345ac63a09b86e\n",
            "Successfully built rouge_score\n",
            "Installing collected packages: rouge_score\n",
            "Successfully installed rouge_score-0.1.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MUSYtN5Da7jM",
        "outputId": "b0e0db77-4632-4345-f107-e20bef1732bc"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HmX5iRVEaXrj",
        "outputId": "77417e4e-065a-40ae-e4a0-da2791fbf2b7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "summary The case was brought by a widow and her daughter who had married a man who owned a number of properties in the tirunelveli district. The husband of the widow had left a will to his wife and children. The widow sold one of the properties to the 2nd defendant for a sum of £500. The appeal was granted and the supreme court was granted the appeal to the supreme Court of India.\n",
            "{'rouge1': Score(precision=0.0445906432748538, recall=0.8356164383561644, fmeasure=0.08466342817487854), 'rouge2': Score(precision=0.023408924652523776, recall=0.4444444444444444, fmeasure=0.04447533009034051), 'rougeL': Score(precision=0.03216374269005848, recall=0.6027397260273972, fmeasure=0.061068702290076333)}\n"
          ]
        }
      ],
      "source": [
        "import transformers \n",
        "from transformers import BartForConditionalGeneration, BartTokenizer, BartConfig \n",
        "import nltk \n",
        "nltk.download('punkt') \n",
        "from nltk.corpus import stopwords \n",
        "from nltk.tokenize import sent_tokenize,word_tokenize \n",
        "from nltk.stem import PorterStemmer \n",
        "import string \n",
        "from rouge_score import rouge_scorer\n",
        "\n",
        "nltk.download('stopwords') \n",
        "stop_words = set(stopwords.words('english'))\n",
        "\n",
        "extracted_text=' ' \n",
        "with open('/content/drive/MyDrive/legal_data/judgement/1953_L_1.txt', 'r') as file: \n",
        "      extracted_text = file.read()\n",
        "      \n",
        "#stemming tokens \n",
        "\n",
        "#function for tokenization and removing stopwords\n",
        "def remove_stop_words(text):\n",
        "    punct_removed_text = text.translate(str.maketrans('','',string.punctuation))\n",
        "    words = nltk.word_tokenize(punct_removed_text)\n",
        "    words = [word for word in words if word.lower() not in stop_words]\n",
        "    return \" \".join(words)\n",
        "\n",
        "\n",
        "#function for stemming\n",
        "def stemming(text):\n",
        "    tokens = text.split(' ')\n",
        "\n",
        "    #defining a Stemmer\n",
        "    stemmer = PorterStemmer()\n",
        "\n",
        "    #stem the tokens \n",
        "    stemmed_tokens = []\n",
        "\n",
        "\n",
        "    for token in tokens:\n",
        "        stemmed_token = stemmer.stem(token)\n",
        "        stemmed_tokens.append(stemmed_token)\n",
        "\n",
        "    #join the stemmed tokens back into a string\n",
        "    stemmed_text = ' '.join(stemmed_tokens)\n",
        "\n",
        "    return stemmed_text\n",
        "\n",
        "text_without_stopwords = remove_stop_words(extracted_text) #removing stopwords (function called)\n",
        "stem_text = stemming(text_without_stopwords)\n",
        "sentences = sent_tokenize(extracted_text)\n",
        "text = \"summarize:\" + stem_text\n",
        "\n",
        "\n",
        "bart_tokenizer = BartTokenizer.from_pretrained('facebook/bart-large-cnn')\n",
        "bart_model = BartForConditionalGeneration.from_pretrained('facebook/bart-large-cnn')\n",
        "    #BART MODEL ------------\n",
        "\n",
        "reference_summary=' '\n",
        "with open('/content/drive/MyDrive/legal_data/summary/full/A1/1953_L_1.txt', 'r') as file:\n",
        "    reference_summary = file.read()\n",
        "\n",
        "bart_inputs = bart_tokenizer.encode(extracted_text,return_tensors='pt', max_length=1024, truncation=True)\n",
        "bart_summary_ids = bart_model.generate(bart_inputs, num_beams=1, max_length=400, early_stopping=True)\n",
        "#     bart_summary = bart_tokenizer.decode(bart_summary_ids[0],skip_special_tokens=True)\n",
        "bart_summary = bart_tokenizer.decode(bart_summary_ids[0],skip_special_tokens=True)\n",
        "print('summary',bart_summary)\n",
        "\n",
        "# Calculate ROUGE scores\n",
        "scorer = rouge_scorer.RougeScorer(['rouge1', 'rouge2', 'rougeL'], use_stemmer=True)\n",
        "scores = scorer.score(str(bart_summary), reference_summary)\n",
        "print(scores)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The case was brought by a widow and her daughter who had married a man who owned a number of properties in the tirunelveli district. The husband of the widow had left a will to his wife and children. The widow sold one of the properties to the 2nd defendant for a sum of £500. The appeal was granted and the supreme court was granted the appeal to the supreme Court of India."
      ],
      "metadata": {
        "id": "rXncU3MbGqKU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import transformers \n",
        "from transformers import BartForConditionalGeneration, BartTokenizer, BartConfig \n",
        "import nltk \n",
        "nltk.download('punkt') \n",
        "from nltk.corpus import stopwords \n",
        "from nltk.tokenize import sent_tokenize,word_tokenize \n",
        "from nltk.stem import PorterStemmer \n",
        "import string \n",
        "\n",
        "nltk.download('stopwords') \n",
        "stop_words = set(stopwords.words('english'))\n",
        "extracted_text=' ' \n",
        "with open('/content/drive/MyDrive/legal_data/judgement/2015_J_10.txt', 'r') as file: \n",
        "      extracted_text = file.read()\n",
        "    \n",
        "sentences = sent_tokenize(extracted_text)\n",
        "\n",
        "reference_summary=' '\n",
        "with open('/content/drive/MyDrive/legal_data/summary/segment-wise/A2/facts/2015_J_10.txt', 'r') as file:\n",
        "    reference_summary = file.read()\n",
        "\n",
        "bart_tokenizer = BartTokenizer.from_pretrained('facebook/bart-large-cnn')\n",
        "bart_model = BartForConditionalGeneration.from_pretrained('facebook/bart-large-cnn')\n",
        "\n",
        "bart_inputs = bart_tokenizer.encode(extracted_text,return_tensors='pt', max_length=1024, truncation=True)\n",
        "bart_summary_ids = bart_model.generate(bart_inputs, num_beams=4, max_length=400, early_stopping=True)\n",
        "bart_summary = bart_tokenizer.decode(bart_summary_ids[0],skip_special_tokens=True) \n",
        "print('bart summary',bart_summary)\n",
        "# print('reference summary',reference_summary)\n",
        "# Calculate ROUGE scores\n",
        "scorer = rouge_scorer.RougeScorer(['rouge1', 'rouge2', 'rougeL'], use_stemmer=True)\n",
        "scores = scorer.score(str(bart_summary), reference_summary)\n",
        "print(scores)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t7i5A2iRDxLp",
        "outputId": "81532a8d-a216-4d3b-b43c-1ed3b01841f0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "bart summary This appeal is preferred against the judgment dated 19 8 2011 passed by the high court of punjab and haryana in criminal appeal no 181 sb of 2000. The high court partly allowed the appeal filed by the appellants thereby confirming the conviction of the appellant with certain modifications. The accused persons were convicted of trespassing into the land belonging to the accused and attempted to forcibly cut the pullas.\n",
            "{'rouge1': Score(precision=0.09429280397022333, recall=0.5428571428571428, fmeasure=0.160676532769556), 'rouge2': Score(precision=0.03980099502487562, recall=0.2318840579710145, fmeasure=0.06794055201698514), 'rougeL': Score(precision=0.08188585607940446, recall=0.4714285714285714, fmeasure=0.13953488372093023)}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "bart summary This appeal is preferred against the judgment dated 19 8 2011 passed by the high court of punjab and haryana in criminal appeal no 181 sb of 2000. The high court partly allowed the appeal filed by the appellants thereby confirming the conviction of the appellant with certain modifications. The accused persons were convicted of trespassing into the land belonging to the accused and attempted to forcibly cut the pullas.\n"
      ],
      "metadata": {
        "id": "q9PAiaDi0Pl-"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "q6u2JFv70KTV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install scikit-learn\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RD-xPER32su1",
        "outputId": "5d956414-ca74-4d14-95fe-53d83bd9ffce"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.9/dist-packages (1.2.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.9/dist-packages (from scikit-learn) (3.1.0)\n",
            "Requirement already satisfied: scipy>=1.3.2 in /usr/local/lib/python3.9/dist-packages (from scikit-learn) (1.10.1)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.9/dist-packages (from scikit-learn) (1.2.0)\n",
            "Requirement already satisfied: numpy>=1.17.3 in /usr/local/lib/python3.9/dist-packages (from scikit-learn) (1.22.4)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import transformers \n",
        "from transformers import BartForConditionalGeneration, BartTokenizer, BartConfig \n",
        "import nltk \n",
        "nltk.download('punkt') \n",
        "from nltk.corpus import stopwords \n",
        "from nltk.tokenize import sent_tokenize,word_tokenize \n",
        "from nltk.stem import PorterStemmer \n",
        "import string \n",
        "import pickle\n",
        "\n",
        "nltk.download('stopwords') \n",
        "stop_words = set(stopwords.words('english'))\n",
        "extracted_text=' ' \n",
        "with open('/content/drive/MyDrive/legal_data/judgement/2015_J_10.txt', 'r') as file: \n",
        "      extracted_text = file.read()\n",
        "    \n",
        "sentences = sent_tokenize(extracted_text)\n",
        "\n",
        "reference_summary=' '\n",
        "with open('/content/drive/MyDrive/legal_data/summary/segment-wise/A2/facts/2015_J_10.txt', 'r') as file:\n",
        "    reference_summary = file.read()\n",
        "\n",
        "bart_tokenizer = BartTokenizer.from_pretrained('facebook/bart-large-cnn')\n",
        "bart_model = BartForConditionalGeneration.from_pretrained('facebook/bart-large-cnn')\n",
        "\n",
        "bart_inputs = bart_tokenizer.encode(extracted_text,return_tensors='pt', max_length=1024, truncation=True)\n",
        "bart_summary_ids = bart_model.generate(bart_inputs, num_beams=4, max_length=400, early_stopping=True)\n",
        "bart_summary = bart_tokenizer.decode(bart_summary_ids[0],skip_special_tokens=True) \n",
        "print('bart summary',bart_summary)\n",
        "# print('reference summary',reference_summary)\n",
        "# Calculate ROUGE scores\n",
        "scorer = rouge_scorer.RougeScorer(['rouge1', 'rouge2', 'rougeL'], use_stemmer=True)\n",
        "scores = scorer.score(str(bart_summary), reference_summary)\n",
        "print(scores)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "81532a8d-a216-4d3b-b43c-1ed3b01841f0",
        "id": "86zC9FMI0dDc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "bart summary This appeal is preferred against the judgment dated 19 8 2011 passed by the high court of punjab and haryana in criminal appeal no 181 sb of 2000. The high court partly allowed the appeal filed by the appellants thereby confirming the conviction of the appellant with certain modifications. The accused persons were convicted of trespassing into the land belonging to the accused and attempted to forcibly cut the pullas.\n",
            "{'rouge1': Score(precision=0.09429280397022333, recall=0.5428571428571428, fmeasure=0.160676532769556), 'rouge2': Score(precision=0.03980099502487562, recall=0.2318840579710145, fmeasure=0.06794055201698514), 'rougeL': Score(precision=0.08188585607940446, recall=0.4714285714285714, fmeasure=0.13953488372093023)}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pickle\n",
        "import transformers\n",
        "from transformers import BartTokenizer, BartForConditionalGeneration, BartConfig\n",
        "\n",
        "# Step 1: Accept a text file\n",
        "text_file = input(\"Enter the path of the text file: \")\n",
        "\n",
        "# Step 2: Load and preprocess the text data\n",
        "with open(text_file, \"r\") as f:\n",
        "    text = f.read()\n",
        "\n",
        "# Step 3: Train a BART model on the text data\n",
        "tokenizer = BartTokenizer.from_pretrained(\"facebook/bart-base\")\n",
        "model = BartForConditionalGeneration.from_pretrained(\"facebook/bart-base\")\n",
        "\n",
        "inputs = tokenizer(text, return_tensors=\"pt\", truncation=True, max_length=1024)\n",
        "summary_ids = model.generate(inputs['input_ids'], num_beams=1, max_length=400, early_stopping=True)\n",
        "summary = tokenizer.decode(summary_ids.squeeze(), skip_special_tokens=True)\n",
        "# summary = tokenizer.decode(summary_ids[0],skip_special_tokens=True)\n",
        "\n",
        "\n",
        "# Step 4: Save the model using pickle\n",
        "with open(\"bart_model.pkl\", \"wb\") as f:\n",
        "    pickle.dump(model, f)\n",
        "\n",
        "# Step 5: Load the model from the saved file and generate a summary\n",
        "with open(\"bart_model.pkl\", \"rb\") as f:\n",
        "    loaded_model = pickle.load(f)\n",
        "\n",
        "# print(\"Input text:\\n\", text)\n",
        "print(\"\\nGenerated summary:\\n\", summary)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "92Trl6xr7vh-",
        "outputId": "18ca9fce-10b4-41f3-9b3c-84d4432b3380"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Enter the path of the text file: /content/drive/MyDrive/legal_data/judgement/1953_L_1.txt\n",
            "\n",
            "Generated summary:\n",
            " one lakshminarayana iyer a hindu brahmin who owned considerable properties in the tirunelveli district died on 13th december 1924 leaving him surviving a widow ranganayaki and a married daughter ramalakshmi. The widow was a widow of the husband of the widow.ramalakshe was a daughter of the wife of the deceasedramalakhshmi had married the plaintiff and had a number of children from him.they were all alive in december 2004 when lakShminaraya died.the widow of a hindi brahman was a hidar.before his death he executed a will on 16th november 1924 the construction of which is in controversy in this appeal.the court of the subordinate judge held that the plaintiff was entitled to maintain the suit.by this will he gave the following directions after my lifetime you the aforesaid ranganayaaki amminal my wife shall till your lifetime enjoy the afore said entire properties the outstandings due to me the debts payable by me and the chit amounts payable by you.after your lifetime ramalakhmamamammy wife of my late son rama ayyar avergal of melagaram village and her heirs shall enjoy them with absolute rights and powers of alienation such as gift exchange and sale from son to grandson and so on for generations.the judge held the followingas regards the payment of maintenance to be made to chinnanmal alias lakšmi ammal wife of our late son hariharamayyan my wife ranganahmammy daughter and wife of ramaayyar.the lord of the court of appeals was not able to make a decision on the matter.the jury was not allowed to make any decision on whether to grant the same as she pleases and obtain a release deed.the trial was not held.ranganayaka entered into possession of the\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        " one lakshminarayana iyer a hindu brahmin who owned considerable properties in the tirunelveli district died on 13th december 1924 leaving him surviving a widow ranganayaki and a married daughter ramalakshmi. The widow was a widow of the husband of the widow.ramalakshe was a daughter of the wife of the deceasedramalakhshmi had married the plaintiff and had a number of children from him.they were all alive in december 2004 when lakShminaraya died.the widow of a hindi brahman was a hidar.before his death he executed a will on 16th november 1924 the construction of which is in controversy in this appeal.the court of the subordinate judge held that the plaintiff was entitled to maintain the suit.by this will he gave the following directions after my lifetime you the aforesaid ranganayaaki amminal my wife shall till your lifetime enjoy the afore said entire properties the outstandings due to me the debts payable by me and the chit amounts payable by you.after your lifetime ramalakhmamamammy wife of my late son rama ayyar avergal of melagaram village and her heirs shall enjoy them with absolute rights and powers of alienation such as gift exchange and sale from son to grandson and so on for generations.the judge held the followingas regards the payment of maintenance to be made to chinnanmal alias lakšmi ammal wife of our late son hariharamayyan my wife ranganahmammy daughter and wife of ramaayyar.the lord of the court of appeals was not able to make a decision on the matter.the jury was not allowed to make any decision on whether to grant the same as she pleases and obtain a release deed.the trial was not held.ranganayaka entered into possession of the\n"
      ],
      "metadata": {
        "id": "_WxwYJctC1Wq"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "MYtPm0Ljye5v"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}